{
  "title": "Lecture 5 CPU Scheduling",
  "cells": [
    {
      "type": "markdown",
      "data": "**When multiple VMs send instructions to the host, which instructions should the host CPU execute first**\n* implement in the hypervisor\n> Suppose there are two VMs, which have the same weight. But only VM 1 has job to do while VM 2 has nothing to do. Non work conserving scheduler is give VM 2 50% of the CPU time anyway. Work-conserving solution is giving VM 1 100% of the CPU time. The utilization is always better for work-serving solution.\n* Utilization:\n  1. working-conserving: the host CPU is idel if and only if there is no runnable VM, the weight acts as guarantees\n  2. Non working-conserving: weight are cap, each VM owns its fraction of CPU\n### CPU Schedulers in Xen\n* Borrowed Virtual Time Scheduling (originally invented to schedule processes in the OS): dispatches a runnable VM with the smallest virtual time first (frequency: every MCU) --> when the virtual time is the same, can choose any one\n  * Each VM has a weight and a virtual time counter\n  * If a VM is scheduled to run, its virtual time is incremented (vi+=(t/wi), t-->the time VM has been running)\n    * if the VM has bigger weight, the virtual time increment is relatively small, therefore, it will be allocated more CPU time which is corresponding the weight \n  * The unit of time is minimum charging unit, MCU, often decided by the frequency of clock interrupts\n![Screen Shot 2018-02-23 at 11.48.13 AM.png](quiver-image-url/AF9AA05FA0B704B3ABE8A09F3F569F7D.png =585x331)\n  * Working-conserving: a vm can warp back in virtual time to gain priority over other VMs\n    * E.g. With warp say 10 MCUs the virtual time starts from -10 instead of 0\n    * Advantages: good fairness  and low overhead implementation on multiprocessor and uniprocessors\n    * Disadvantages: no non-work conserving support (when it is necessary for strict VM isolation)\n* Simple earliest deadline first (EDF) (rely on the concept of deadlines): each VM specifies its CPU requirement with a tuple(si, pi, xi)\n  * VM i wants to receive at least s_i units of time in each period of length p_i\n    * si=1, pi=2, the VM wants one time slot for every two time slot\n  * x_i(binary variable): whether to receive extra CPU time, whether the VM wants to have work-conserving mode\n    * if set to one, the VM can potentially get more than it requested\n  * Foreach VM, the scheduler keeps two variables:\n    1. di: time at which VM i's current period ends\n    2. ri: remaining CPU time in the current period\n  * at each time slots, among the VMs whose r_i is positive scheudle the one with earliest deadline to run ( ties are broken arbitrarily)\n  * Nonn-work conserving: when x_i =0, non working conserving, the VM is made runnable periodically, --> r_i is reset to s_i at the strt of each period\n    * the least common multiple of the periods is 14, so the scheudling pattern will repeat every 14 slots\n  * Schedulability: any VM set is schedulable if and only if sum(si/pi)<=1\n  * Work-conserving: when x_i=1, a VM is always runnable, r_iis reset to s_i immediately after it reduces to 0 and d_i is incremented by p_i at the same time\n  * Features: fairness depends on the value of the period, WC&NWC\n  * Disadvantage: implements per-CPU scheduling, lacks global load balancing on multiprocessors\n* Creadit Scheduler: default schedular in Xen, similar to BVT, each VM is assigned a weight and a cap\n  * weight: default value is 256\n  * Cap (percentage): default 0 for WC, optionally fix the CPU this VM can get even in NWC\n  * A VM has priority which can be one of two values: over/under representing whether this VM has or not execeed its fair share of CPU resource in the ongoing accounting period\n  * Each CPU keeps two FIFO queue of runnable VMs, over and under\n    * The CPU check the under queue pop the VM, if there is nothing in under queue, then check over queue"
    }
  ]
}