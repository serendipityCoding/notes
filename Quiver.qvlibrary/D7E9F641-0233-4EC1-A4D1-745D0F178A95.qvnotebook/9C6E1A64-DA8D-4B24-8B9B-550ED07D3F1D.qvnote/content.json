{
  "title": "Lecture 6 Data center networking - Basics, Topology, Traffic",
  "cells": [
    {
      "type": "markdown",
      "data": "#### Basic Concepts\n* Nodes (end hosts + switches/routers) + Links (cable, fiber wireless)\n*middleboxes are used to process packets (check trojen, ddos)*\n*wireless: mobile wireless(3G, 4G) + wifi*\n* Switch approaches:\n  1. circuit switching: dedicated link, connection oriented\n  2. packet switching: shared link, connectionless, not physical set-up\n* Address: byte-string which identifies anode\n  1. unicast: node specific\n  2. broadcast: all nodes on the network\n  3. multicast: group/subsets of nodes\n* Multiplexing:\n  1. Time division multiplexing\n  2. Frequency division multiplexing\n* Statistical multiplexing: on demand time division\n* Performance:\n  1. bandwidth, throughput: amount of data transmitted per unit time\n  2. latency: total time from one end to another\n    * latency = propagation (ususally 0 unless very far)+ transmission (higher bandwidtth, higher tranmission) + queue (buffer space in the switch)\n    * relative importance:\n      * 1B flow: queueing delay dominates (miliseconds) --> build dedicated link, remove possible queueing\n      * 25MB flow: transmission delay (seconds)\n* Layering architecture: layering with well-defined interfaces\n  *  OSI: application--> presentation --> session --> transport --> network -->data link --> physical\n  *  TCP/IP: application --> transport --> network --> data link/MAC -->physical\n    * hosts will connect to the server and will goes to different sockets but the same port number (default for TCP: 80)\n    * IP: connectionless, packet-based, inherently unreliable, header format\n    * Transport Layer: provide reliable data transfer to applications over IP network\n      * point-to-point, connection-oriented\n      * flow-control: not send too fast for the receiverto process --> recv window\n        * receiver has some buffer space, so the sender ill not overflow the buffer by sending too fast, sender can liit the amout of un-acked dara to reciver's rwnd value\n      * congestion control: avoid congestion collapse (too many sources sending too much) --> cwnd, \n        * not to overflow the network\n        * congestion signals\n          1. lost packets (buffer overflow at router)\n          2. long delays (queue in router buffers)\n          *packet drops may not be caused by congestions in wireless network, deplicated ACKs may be caused by unordered packets (change of network path, some packets arrive late but not dropped, late arrival)*\n        * AIMD: additive increase, multilicative decrease\n          *why notjust renew the sending rate ater some timebased o the average performance? the network condition changes every second*\n          **drawbacks** *, late reaction, when the cmnd grows more than the buffer, the switch buffer slowly building up. can only wait until the switch buffer is used up and droedtwo packets, then it can decrease the cwnd. That is why the decrease is so dramatically because when the sender realize the problem, it has been along time already*\n      * packet loss can be detected by timeoutsand dupicated ACKs\n      *suppose there is a litte chunk of data to send, pkt 1 and pkt2. Pkt 2 islost, pkt s1 is sent. When the receiver receive the pkt 1 and send out ack 2, for receiver, it does not know how many pkts are there. So even though there are lost pkts, the receiver cannot send duplicate ACKs. Therefore, using tieouts may helpin this case. Whenever the sender send a pkt, it wil set a timer (Minimum IPO)*\n#### Topology\n* Scale:\n  * Clos:use many low-radix switches in multiple stagestscaleto arbitrary size\n    * substantial path diverstyand redundancy --> fault tolerant\n  *"
    }
  ]
}