{
  "title": "Lecture 7",
  "cells": [
    {
      "type": "markdown",
      "data": "* Multpath in Fat-tree: there are multiple shortest paths from one host to another\n  * ECMP: consisien hashing of five tuples --> packets of the same flow go through the same path\n    * Advantage:\n      1. no need to remember the status\n      2. hashing uniformly spread flows across all links --> load balancing\n      3. each port has an equal nunmber of flows on average\n      4. easy to implement in hardware\n* Latency: the mixed nature causes unbalanced traffic with ECMP\n  * E.g. one elephant and one mice going through a switch, it is possible that ECMP hashes them to the same output port -- hash collision, since the elphant flow has more pkts, the mice flow is queued up behind pkts of the elephant --> cause long queueing delay \n  * latency at 99th can be much worse than average latency\n    * for many applications, they use distributed computing method, one request may need several servers to work on this job (distributed pattern), so need to wait all the response sent back to the client \n    ** the final reponse time depends on the slowest flow, the tail latecny decides the application reponse**\n    * Solutions:\n      1. reduce queue length at switches: TCP use packets drops as a congestions signal --> throttle the elephants before they use up the buffer\n        * ECN: some switch is experiencing congestion, so congestion controlcan be done earlier --> not drop packets\n          * DSCP:set the priority of the flow\n          * ECT: indicate if the end host use ECN\n          * CE(congestion experience): if the current buffer exceed a threshold (have some buffer left), inform in advance in process of congestion --> the threshold is usually much smaller than the buffer size\n            * when the receiver set the echo flag in the TCP ACK\n            * the sender get the ECN info and performa congestion control\n          * alpha is the percentage of packets being marked with ECN\n            * large alpha --> lots of congestion --> slow down -->  reduce cwnd\n            **instead of cutting cwnd to half, DCTCP have earlier control (no packets drop), so no need to change so dramatically --> reduce the queueing delay --> shorter tranmission time**\n      2. prioritize mice flows \n        * pFabric(difficult to implement): decouple flow scheduling from congestion control(small flow first and big flow wait)--> having preknowledge of how much flow will be sent, how many packets each flow have, the number of priorities at the switches in the reality is relatively small\n          * each packet encodes a priority number in its header\n          * when the buffer is full, switches will do priority dropping (drop big flow, which is difficult to implement in the hardware) instead of drop the coming tail packets\n          * when the loads is high, pFabric is doing nearly an ideal job compared with the DCTCP\n      3. better multipathing\n        * RepFlow: launch two network sockets with different src port, make sure the ECMP hsh the original and replicate flow to differn paths, trade average case with worst case\n          * no need to change kernal or switches, work for any transport protocals\n          * need overhead, does not fix the problem (does not reedy hash collision)\n      4. monitor link utilization\n          * Congestion-aware Load Balancing: modify switch data plane, for a new flow, no hashing, collect the path load for all/some of the equal cost paths, make a load-balancing decision--> pick the least load work\n          "
    }
  ]
}