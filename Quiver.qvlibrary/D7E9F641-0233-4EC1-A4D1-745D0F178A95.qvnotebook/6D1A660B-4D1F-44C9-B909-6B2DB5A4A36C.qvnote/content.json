{
  "title": "Lecture 4",
  "cells": [
    {
      "type": "markdown",
      "data": "####how to schedule a large amount of varied-size jobs to the machines based on what they need in a resource fully-utilized way\n* Current situation: diverse workoads + increasing cluster sizes + growing job arrival rates (in a unit time, cluster see more and amorejobs requiring resources)\n* Generally, jobs can be categorized in two parts: batch job + service job\n![Screen Shot 2018-02-09 at 10.40.55 AM.png](quiver-image-url/46B333D32F694B9C180AEC046ED43EAF.png =587x359)\n  * when scheduling batch jobs, the scheudler has to be very fast, the quality of scheduler decision does not matter too much because they usually just  execute for ten minutes and then they are gone (trade-off)\n  * when scheudling servic ejob, it is kind of the opposite, the scheduler sees a job, no need to rush, focus on how to optimize the resource allocation because they are going to be running for one month --> take longer time to make the decision\n  * the diffulty is making a scheduler for both kinds of jobs\n* breaking up into indeendent shedulers and various shedulers working on certain kind of jobs (e.g. tensorflow, spark, hadoop all have their own scheduler\n  * the problem is then it is necessary to have a cluster scheduler to divide the cluster among these different schedulers\n* Cluster scheduling: how to divide and allocate the resources to the different machines. (how much space, how many mmachines is needed to for tensorflow)\n![Screen Shot 2018-02-09 at 11.04.49 AM.png](quiver-image-url/282B2A2D1E169EA370A4D7BFA0D390E9.png =508x322)\n![Screen Shot 2018-02-09 at 11.08.24 AM.png](quiver-image-url/BA69DC0776E758AABA7A9FB19EDD3027.png =502x323)\n* Two-level scheduling: the scheduler only sees the machine allocated to itself\n  * cluster scheduling divide the machines to different schedulers\n  * drawback: hidden information for schedulers\n* Mesos: a common resource sharing layer over which diverse frameworks can run ( a operatig system kernal of a gigantic machine)\n  * Goals:\n    1. high utilization of rsources\n    2. support diverse fraeworks\n    3. scalability\n    4. reliability\n  * design elements: fine-grained sharing (allocate at the level of tasks within a job --> utilization, latency, data locality ++) + resource offers (give options to the scheduler on the resource allocation to choose the proper one, no need to the what the framwork needs)\n  ![Screen Shot 2018-02-09 at 11.36.11 AM.png](quiver-image-url/B8F5C276C6B1A03614E174D23A9CB592.png =502x323)\n  * Disadvantage:\n    * the offers made may not suit what the framwork need\n![Screen Shot 2018-02-09 at 11.41.13 AM.png](quiver-image-url/6DF65671CE7B864D049726F2F52C1E1F.png =503x385)\n* shared-state(inspired by omega scheduler): expose the entire information to each individual framework, before the framework actually commits to the resources, the omega scheduler interrupts in, check if there are conflicted resources being asked and allocate the resources and update the current cluster state\n**the cluster has to make sure that all the schedulers has the consistent views of the current cluster using state (the number is large)**\n"
    }
  ]
}